<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hao Shen - AUST</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="icon" type="image/x-icon" href="favicon/favicon.ico"/>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="menu-container">
        <div class="menu">
            <a href="#">Home</a>
            <a href="#biography">Biography</a>
            <a href="#news">News</a>
            <a href="#publications">Publications</a>
            <a href="#services">Services</a>
            <a href="#awards">Awards</a>
            <a href="#projects">Projects</a>
            <a href="#resources">Resources</a>
        </div>
    </div>

    <div class="container">
        <div class="profile-header">
            <a href="https://ggaq.aust.edu.cn/info/1097/1776.htm" target="_blank"><img src="./picture/hao_sketch.jpg" alt="Hao Shen" class="profile-img"></a>
            
            <div class="profile-info">
                <div class="profile-title">
                    <h1><img src="./picture/sign.png">(Hao Shen) ☕🏃‍♂️⛹️🏸🎱📙</h1>
                    <p>Lecturer | <a href="https://www.aust.edu.cn/" target="_blank">Anhui University of Science and Technology</a> | <a href="https://ggaq.aust.edu.cn/index.htm" target="_blank">School of Public Safety and Emergency Management</a></p>
                    <p>Research Areas: Deep Learning · Low-Level Vision · Image Restoration</p>
                </div>
                
                <div class="social-links" id="social-links">
                    <a href="mailto:haoshenhs@gmail.com" class="social-btn">
                        <i class="fas fa-envelope"></i> Email
                    </a>
                    <a href="https://scholar.google.com/citations?user=l1MhibgAAAAJ&hl=zh-CN" class="social-btn" target="_blank">
                        <i class="fas fa-graduation-cap"></i> Google Scholar
                    </a>
                    <a href="https://github.com/it-hao" class="social-btn" target="_blank">
                        <i class="fab fa-github"></i> GitHub
                    </a>
                    <a href="https://orcid.org/0000-0002-1945-4016" class="social-btn" target="_blank">
                        <i class="fab fa-orcid"></i> ORCID
                    </a>
                    <a href="https://surl.amap.com/2XBh41n1y1HK" class="social-btn" target="_blank">
                        <i class="fa-solid fa-map-location-dot"></i> Hefei, Anhui
                    </a>
                </div>
            </div>
        </div>
        
        <!-- 个人简介 -->
        <!-- <div class="section" id="biography">
            <h2 class="section-title">Biography</h2>

            <p style="text-align:justify; text-justify:inter-ideograph;padding-right:10px;"> Hi, I am Hao Shen! I am currently a Lecturer at Anhui University of Science and Technology (AUST). Previously, I obtained my Ph.D. degree 🎉🎉🎉 from the <a href="https://ci.hfut.edu.cn/" target="_blank" style="color: #483D8B; font-size: 1.em"> School of Computer Science and Information Engineering</a>, <a href="https://www.hfut.edu.cn/" target="_blank" style="color: #483D8B; font-size: 1.em">Hefei University of Technology (HFUT)</a>, supervised by Professor <a href="https://scholar.google.com/citations?user=yELU6JcAAAAJ&hl=zh-CN" target="_blank">Zhong-Qiu Zhao👍</a>. 
            I was funded by the China Scholarship Council (CSC) and spent a one-year exchange study at Nanyang Technological University, Singapore, supervised by Prof. <a href="https://personal.ntu.edu.sg/exdjiang/default.htm" target="_blank">Xudong Jiang (IEEE Fellow) 🤞</a>. Meanwhile, I am also lucky to have opportunities to collaborate with <a href="https://henghuiding.github.io/" target="_blank" style="color: #483D8B; font-size: 1.em">Henghui Ding (Professor at FDU) 🤞</a> and <a href="https://yulunzhang.com/" target="_blank" style="color: #483D8B; font-size: 1.em">Yulun Zhang (Professor at SJTU) 🤞 </a>.
            My research focuses on low-level vision tasks, including image super-resolution, image dehazing, and image denoising🔥🔥🔥. </p>
            <p style="text-align:justify; text-justify:inter-ideograph;padding-right:10px;">
            If you'd like to work together or get in contact with me, please feel free to email <a href="mailto:haoshenhs@gmail.com">haoshenhs@gmail.com</a>.
            </p>
        </div> -->
        <!-- 个人简介 -->
        <div class="section" id="biography">

            <h2 class="section-title">Biography </h2> 

            <div class="language-toggle">
                    <button id="btn-zh" class="active">中文</button>
                    <button id="btn-en">English</button>
            </div>
            <div class="biography-content">
                <!-- 中文版本 -->
                <div id="biography-zh" class="language-version active">
                    <p style="text-align:justify; text-justify:inter-ideograph;padding-right:10px;"> 现任安徽理工大学公共安全与应急管理学院讲师，2024年12月毕业于合肥工业大学计算机与信息学院，获工学博士学位（导师：<a href="https://scholar.google.com/citations?user=yELU6JcAAAAJ&hl=zh-CN" target="_blank">赵仲秋教授</a>）。2023年10月至2024年10月作为国家公派联合培养博士生在新加坡南洋理工大学电气与电子工程学院从事合作研究（导师：<a href="https://personal.ntu.edu.sg/exdjiang/default.htm" target="_blank">Jiang Xudong教授</a>）。入选<a href="https://mp.weixin.qq.com/s/KhozoDHnFoNAwJiH4BLRRQ" target="_blank" style="color: #483D8B">2024年度中国科协青年人才托举工程博士生专项计划</a>（托举学会：中国计算机学会），荣获2024年博士研究生国家奖学金和2021年硕士研究生国家奖学金。主要从事人工智能、计算机视觉研究，重点关注自然成像和遥感成像下的底层视觉任务，包括图像去雾、图像超分辨率重建和图像去噪✨✨✨等。近年来在IEEE TIP、IEEE TGRS、PR、CVPR、AAAI、ACM MM、ECAI、ICME等国际期刊和会议上发表10余篇学术论文，其中以第一作者身份发表6篇论文（含CCF-A类论文3篇）。主持国家自然科学基金青年（C类）、校级高层次人才等项目。</p>
                </div>
                <!-- 英文版本 -->
                <div id="biography-en" class="language-version">
                    <p style="text-align:justify; text-justify:inter-ideograph;padding-right:10px;"> I am currently a Lecturer at Anhui University of Science and Technology (AUST). Previously, I obtained my Ph.D. degree 🎉🎉🎉 from the <a href="https://ci.hfut.edu.cn/" target="_blank" style="color: #483D8B; font-size: 1.em"> School of Computer Science and Information Engineering</a>, <a href="https://www.hfut.edu.cn/" target="_blank" style="color: #483D8B; font-size: 1.em">Hefei University of Technology (HFUT)</a> in December 2024, supervised by Professor <a href="https://scholar.google.com/citations?user=yELU6JcAAAAJ&hl=zh-CN" target="_blank">Zhong-Qiu Zhao👍</a>. From October 2023 to October 2024, I was funded by the China Scholarship Council (CSC) and spent a one-year exchange study at Nanyang Technological University, Singapore, supervised by Prof. <a href="https://personal.ntu.edu.sg/exdjiang/default.htm" target="_blank">Xudong Jiang (IEEE Fellow) 🤞</a>. During this time, I am also lucky to have opportunities to collaborate with <a href="https://henghuiding.github.io/" target="_blank" style="color: #483D8B; font-size: 1.em">Henghui Ding (Professor at FDU) 🤞</a> and <a href="https://yulunzhang.com/" target="_blank" style="color: #483D8B; font-size: 1.em">Yulun Zhang (Professor at SJTU) 🤞 </a>. My research focuses on Artificial Intelligence and Computer Vision, with a focus on low-level vision tasks, including image super-resolution, image dehazing, and image denoising ✨✨✨. In recent years, I have published over 10 academic papers in international conferences and journals, including IEEE TIP, IEEE TGRS, PR, CVPR, AAAI, ACM MM, and ECAI, six of which he was the first author of (including three CCF-A papers).</p>
                    <p style="text-align:justify; text-justify:inter-ideograph;padding-right:10px;"> If you'd like to work together 🤝 or get in contact with me, please feel free to email <a href="mailto:haoshenhs@gmail.com">haoshenhs@gmail.com</a>.
                    </p>
                </div>
                
            </div>
        </div>
        
        <!-- 新闻 -->
        <div class="section" id="news">
            <h2 class="section-title">News</h2>
            <div class="news-container">
                <div class="news-item">
                    <time>[10, 2025]</time> One paper is accepted by <b>IEEE TMM</b>.
                </div>
                <div class="news-item">
                    <time>[08, 2025]</time> The Young Scientists Fund (C Class) has been successfully approved.
                </div>
                <div class="news-item">
                    <time>[06, 2025]</time> One paper is accepted by <b>IEEE TIP</b>.
                </div>
                <div class="news-item">
                    <time>[01, 2025]</time> I was supported by the <b>Youth Talents Support Project - Doctoral Student Special Program </b> 🎉🎉🎉 
                </div>
                <div class="news-item">
                    <time>[09, 2024]</time> One paper is accepted to <b>IEEE TGRS</b>. I was awarded the National Scholarship for Graduate Student.
                </div>
                <div class="news-item">
                    <time>[02, 2024]</time> One paper is accepted to <b>CVPR 2024</b>. Congrats. to <a href="https://xiaofeng-life.github.io/" target="_blank" style="color: #483D8B">Xiaofeng</a>.
                </div>
            </div>
        </div>
        
        <!-- 代表性论文 -->
        <div class="section" id="publications">
            <h2 class="section-title">Selected Publications</h2>
            
            <div class="publication-item">
                <div class="publication-title">Spatial Frequency Modulation Network for Efficient Image Dehazing</div>
                <div class="publication-authors"><b>Hao Shen</b>, Henghui Ding, Yulun Zhang, Zhong-Qiu Zhao*, Xudong Jiang</div>
                <div class="publication-venue">IEEE Transactions on Image Processing (TIP), 2025</div>
                <div class="publication-links">
                    <a href="resources/ShenHao_SFMN_TIP_2025.pdf" target="_blank"><i class="fas fa-file-pdf"></i> PDF</a>
                    <a href="https://github.com/it-hao/SFMN" target="_blank"><i class="fas fa-code"></i> Code</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">Spatial-Frequency Adaptive Remote Sensing Image Dehazing with Mixture of Experts</div>
                <div class="publication-authors"><b>Hao Shen</b>, Henghui Ding, Yulun Zhang, Xiaofeng Cong, Zhong-Qiu Zhao*, Xudong Jiang</div>
                <div class="publication-venue">IEEE Transactions on Geoscience and Remote Sensing (TGRS), 2024</div>
                <div class="publication-links">
                    <a href="resources/ShenHao_SFAN_TGRS_2024.pdf" target="_blank"><i class="fas fa-file-pdf"></i> PDF</a>
                    <a href="https://github.com/it-hao/SFAN" target="_blank"><i class="fas fa-code"></i> Code</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">Mutual Information-driven Triple Interaction Network for Efficient Image Dehazing</div>
                <div class="publication-authors"><b>Hao Shen</b>, Zhong-Qiu Zhao*, Yulun Zhang, Zhao Zhang*</div>
                <div class="publication-venue">ACM International Conference on Multimedia (ACM MM), 2023, Oral Presentation</div>
                <div class="publication-links">
                    <a href="resources/ShenHao_MITNet_MM_2023.pdf" target="_blank"><i class="fas fa-file-pdf"></i> PDF</a>
                    <a href="https://github.com/it-hao/MITNet" target="_blank"><i class="fas fa-code"></i> Code</a>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">Adaptive Dynamic Filtering Network for Image Denoising</div>
                <div class="publication-authors"><b>Hao Shen</b>, Zhong-Qiu Zhao*, Wandi Zhang</div>
                <div class="publication-venue">AAAI Conference on Artificial Intelligence (AAAI), 2023 </div>
                <div class="publication-links">
                    <a href="resources/ShenHao_ADFNet_AAAI_2024.pdf" target="_blank"><i class="fas fa-file-pdf"></i> PDF</a>
                    <a href="https://github.com/it-hao/ADFNet" target="_blank"><i class="fas fa-code"></i> Code</a>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">Joint Operation and Attention Block Search for Lightweight Image Restoration</div>
                <div class="publication-authors"><b>Hao Shen</b>, Zhong-Qiu Zhao*, Wenrui Liao, Weidong Tian, De-Shuang Huang</div>
                <div class="publication-venue">Pattern Recognition (PR), 2022 </div>
                <div class="publication-links">
                    <a href="resources/ShenHao_JSNet_PR_2023.pdf" target="_blank"><i class="fas fa-file-pdf"></i> PDF</a>
                    <a href="https://github.com/it-hao/JsNet" target="_blank"><i class="fas fa-code"></i> Code</a>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">Mid-weight Image Super-resolution with Bypass Connection Attention Network</div>
                <div class="publication-authors"><b>Hao Shen</b>, Zhong-Qiu Zhao*</div>
                <div class="publication-venue">European Conference on Artificial Intelligence (ECAI), 2020 </div>
                <div class="publication-links">
                    <a href="resources/ShenHao_BCAN_ECAI_2020.pdf" target="_blank"><i class="fas fa-file-pdf"></i> PDF</a>
                    <a href="https://it-hao.github.io/" target="_blank"><i class="fas fa-code"></i> Code</a>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">Cross-Domain Knowledge Distillation for Low-Resolution Human Pose Estimation</div>
                <div class="publication-authors">Zejun Gu, Zhong-Qiu Zhao*, Henghui Ding <b>Hao Shen</b>, Zhao Zhang, De-Shuang Huang</div>
                <div class="publication-venue">IEEE Transactions on Multimedia (TMM), 2025 </div>
                <div class="publication-links">
                    <a href="https://arxiv.org/pdf/2405.11448" target="_blank"><i class="fas fa-file-pdf"></i> PDF</a>
                    <a href="https://github.com/guzejungithub/CDKD" target="_blank"><i class="fas fa-code"></i> Code</a>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">Adaptive Branch Selection for Accelerate Image Super-Resolution</div>
                <div class="publication-authors">Cheng Ding, Zhong-Qiu Zhao*, <b>Hao Shen</b>, Xiufeng Liu</div>
                <div class="publication-venue">The Visual Computer, 2025 </div>
                <div class="publication-links">
                    <a href="resources/DingCheng_TVC_2025.pdf" target="_blank"><i class="fas fa-file-pdf"></i> PDF</a>
                    <a href="https://github.com/dcgithubtools/ABS" target="_blank"><i class="fas fa-code"></i> Code</a>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">A Semi-supervised Nighttime Dehazing Baseline with Spatial-Frequency Aware and Realistic Brightness Constraint</div>
                <div class="publication-authors">Xiaofeng Cong, Jie Gui, Jing Zhang, Junming Hou, <b>Hao Shen</b></div>
                <div class="publication-venue">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024 </div>
                <div class="publication-links">
                    <a href="resources/CongXiaofeng_SFSNiD_CVPR_2024.pdf" target="_blank"><i class="fas fa-file-pdf"></i> PDF</a>
                    <a href="https://github.com/Xiaofeng-life/SFSNiD" target="_blank"><i class="fas fa-code"></i> Code</a>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">Test Time Adaptation via Self-Training with Future Information</div>
                <div class="publication-authors">Xin Wen, <b>Hao Shen</b>, Zhong-Qiu Zhao*</div>
                <div class="publication-venue">Journal of Electronic Imaging, 2024 </div>
                <div class="publication-links">
                    <a href="resources/WenXin_JIE_2024.pdf" target="_blank"><i class="fas fa-file-pdf"></i> PDF</a>
                    <a href="https://it-hao.github.io/" target="_blank"><i class="fas fa-code"></i> Code</a>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">Contextual Feature Modulation Network for Efficient Super-Resolution</div>
                <div class="publication-authors">Wandi Zhang, <b>Hao Shen</b>, Zhong-Qiu Zhao*</div>
                <div class="publication-venue">International Conference on Intelligent Computing (ICIC), 2024 </div>
                <div class="publication-links">
                    <a href="resources/Zhang_Wandi_ICIC_2024.pdf" target="_blank"><i class="fas fa-file-pdf"></i> PDF</a>
                    <a href="https://it-hao.github.io/" target="_blank"><i class="fas fa-code"></i> Code</a>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">Global Routing Between Capsules</div>
                <div class="publication-authors">Ran Chen, <b>Hao Shen</b>, Zhong-Qiu Zhao*, Yi Yang</div>
                <div class="publication-venue">Pattern Recognition (PR), 2024 </div>
                <div class="publication-links">
                    <a href="resources/ChenRan_GR-CapsNet_PR_2024.pdf" target="_blank"><i class="fas fa-file-pdf"></i> PDF</a>
                    <a href="https://github.com/cwpl/GR-CapsNet" target="_blank"><i class="fas fa-code"></i> Code</a>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">Rethinking Pan-sharpening via Spectral-band Modulation</div>
                <div class="publication-authors">Xinyang Liu, Junming Hou, Xiaofeng Cong, <b>Hao Shen</b>, Liangjian Deng, Jianwei You</div>
                <div class="publication-venue">IEEE Transactions on Geoscience and Remote Sensing (TGRS), 2023 </div>
                <div class="publication-links">
                    <a href="resources/LiuXinyang_SSMNet_TGRS_2023.pdf" target="_blank"><i class="fas fa-file-pdf"></i> PDF</a>
                    <a href="https://github.com/ez4lionky/SSMNet" target="_blank"><i class="fas fa-code"></i> Code</a>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">Residual Attention Block Search for Lightweight Image Super-Resolution</div>
                <div class="publication-authors">Zhong-Qiu Zhao*, Wenrui Liao, <b>Hao Shen</b>, Weidong Tian</div>
                <div class="publication-venue">International Conference on Multimedia and Expo (ICME), 2021 </div>
                <div class="publication-links">
                    <a href="resources/LiaoWenrui_MRAN_ICME_2021.pdf" target="_blank"><i class="fas fa-file-pdf"></i> PDF</a>
                    <a href="https://github.com/it-hao/JsNet" target="_blank"><i class="fas fa-code"></i> Code</a>
                </div>
            </div>

        </div>

        <!-- Academic Service Section -->
        <div class="section" id="services">
            <h2 class="section-title">Academic Service</h2>
            <ul class="service-list">
                <li style="margin: 5px 0px 0px 0px">
                    ACM International Conference on Multimedia (ACM MM) <a href="https://www.acmmm2023.org/" target="_blank" rel="nofollow" style="color:#DA1212;">2023</a>, <a href="https://2024.acmmm.org/" target="_blank" rel="nofollow" style="color:#DA1212;"> 2024</a>
                </li>
                <li style="margin: 5px 0px 0px 0px">
                    International Joint Conference on Artificial Intelligence (IJCAI) <a href="https://ijcai24.org/" target="_blank" rel="nofollow" style="color:#DA1212;"> 2024</a>, <a href="https://ijcai25.org/" target="_blank" rel="nofollow" style="color:#DA1212;"> 2025</a>
                </li>
                <li style="margin: 5px 0px 0px 0px">
                    AAAI Conference on Artificial Intelligence (AAAI) <a href="https://aaai.org/Conferences/AAAI-22/" target="_blank" rel="nofollow" style="color:#DA1212;"> 2022</a>, <a href="https://aaai.org/Conferences/AAAI-23/" target="_blank" rel="nofollow" style="color:#DA1212;"> 2023</a>, <a href="https://aaai.org/Conferences/AAAI-24/" target="_blank" rel="nofollow" style="color:#DA1212;"> 2024</a>
                </li>
                <li style="margin: 5px 0px 0px 0px">
                    European Conference on Artificial Intelligence (ECAI) <a href="https://ecai2023.eu/" target="_blank" rel="nofollow" style="color:#DA1212;">2023</a>, <a href="https://ecai2024.eu/" target="_blank" rel="nofollow" style="color:#DA1212;"> 2024</a>, <a href="https://ecai2025.eu/" target="_blank" rel="nofollow" style="color:#DA1212;"> 2025</a>
                </li>
                <li style="margin: 5px 0px 0px 0px">
                    <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83" target="_blank" rel="nofollow" style="color:black;">IEEE Transactions on Image Processing (TIP)</a> <br>
                </li>
                <li style="margin: 5px 0px 0px 0px">
                    <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046" target="_blank" rel="nofollow" style="color:black;">IEEE Transactions on Multimedia (TMM)</a> <br>
                </li>
                <li style="margin: 5px 0px 0px 0px">
                    <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76" target="_blank" rel="nofollow" style="color:black;">IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</a> <br>
                </li>
                <li style="margin: 5px 0px 0px 0px">
                    <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6221021" target="_blank" rel="nofollow" style="color:black;">IEEE Transactions on Systems, Man and Cybernetics: Systems (TSMC)</a> <br>
                </li>
                <li style="margin: 5px 0px 0px 0px">
                    <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7433297" target="_blank" rel="nofollow" style="color:black;">IEEE Transactions on Emerging Topics in Computational Intelligence (TETCI)</a> <br>
                </li>
                <li style="margin: 5px 0px 0px 0px">
                    <a href="https://www.sciencedirect.com/journal/information-fusion" target="_blank" rel="nofollow" style="color:black;">
                        Information Fusion (INFFUS)
                    </a> <br>
                </li>
                <li style="margin: 5px 0px 0px 0px">
                    <a href="https://www.sciencedirect.com/journal/engineering-applications-of-artificial-intelligence" target="_blank" rel="nofollow" style="color:black;">
                        Engineering Applications of Artificial Intelligence (EAAI)
                    </a> <br>
                </li> 
                <li style="margin: 5px 0px 0px 0px">
                    <a href="https://www.sciencedirect.com/journal/knowledge-based-systems" target="_blank" rel="nofollow" style="color:black;">Knowledge-Based Systems (KBS)</a> <br>
                </li>
                <li style="margin: 5px 0px 0px 0px">
                    <a href="https://www.sciencedirect.com/journal/signal-processing" target="_blank" rel="nofollow" style="color:black;">Signal Processing</a> <br>
                </li>
                <li style="margin: 5px 0px 0px 0px">
                    <a href="https://www.sciencedirect.com/journal/neurocomputing" target="_blank" rel="nofollow" style="color:black;">Neurocomputing</a> <br>
                </li>
                <li style="margin: 5px 0px 0px 0px">
                    <a href="https://www.mi-research.net/" target="_blank" rel="nofollow" style="color:black;">Machine Intelligence Research (MIR)</a> <br>
                </li>
                <li style="margin: 5px 0px 0px 0px">
                    <a href="https://digital-library.theiet.org/journal/iet-ipr" target="_blank" rel="nofollow" style="color:black;">IET Image Processing (IET-IPR)</a> <br>
                </li>
                <li style="margin: 5px 0px 0px 0px">
                    <a href="https://www.sciencedirect.com/journal/image-and-vision-computing/" target="_blank" rel="nofollow" style="color:black;">Image and Vision Computing (IVC)</a> <br>
                </li>
            </ul>
        </div>

        
        <!-- 荣誉奖项 -->
        <div class="section" id="awards">
            <h2 class="section-title">Honors and Awards</h2>
            <ul class="honors-list">
                <li><strong>2025:</strong> China Association for Science and Technology Young Talent Support Project - Doctoral Student Special Program | 中国科协博士生专项计划 (CCF)</li>
                <li><strong>2024:</strong> National Scholarship for Graduate Student, China | 博士研究生国家奖学金</li>
                <li><strong>2023:</strong> Chinese Scholarship Council Funding, China | CSC奖学金</li>
                <li><strong>2021:</strong> Outstanding Graduate, Hefei University of Technology | 校优秀毕业生</li>
                <li><strong>2020:</strong> National Scholarship for Graduate Student, China | 硕士研究生国家奖学金</li>
                <li><strong>2018:</strong> Outstanding Graduate, Anhui Province | 安徽省优秀毕业生</li>
                <li><strong>2017:</strong> National Encouragement Scholarship, China | 国家励志奖学金</li>
                <li><strong>2015:</strong> National Encouragement Scholarship, China | 国家励志奖学金</li>
            </ul>
        </div>

        <!-- Projects Section -->
        <div class="section" id="projects">
            <h2 class="section-title">Projects</h2>
            <ul class="projects-list">
                <li>XXXXX的任务自适应图像复原方法研究 (No. 62502006), 2026.01-2028.12, 主持<br>国家自然科学基金青年项目(C类) (The Young Scientists Fund of National Natural Science Foundation of China)</li>
                <li>XXXXX的一体化图像复原方法研究 (No. 2025yjrc0015), 2025.04-2027.04, 主持<br>校级高层次人才科研启动基金 (Scientific Research Foundation for High-Level Talents of AUST)</li>
                <li>面向XXXXX的低照度图像增强 (No. XXXXXXXXX), 主持<br>企业委托项目</li>
            </ul>
        </div>

        <!-- Resources Section -->
        <div id="resources" class="section">
            <h2 class="section-title">Resources</h2>
            <ul class="service-list">
                <li style="margin: 5px 0px 0px 0px">
                    <a href="https://ccfddl.com/" target="_blank" rel="nofollow" style="color: #483D8B"> CCF Deadlines </a> <br>
                </li>

                <li style="margin: 5px 0px 0px 0px">
                    <a href="https://aideadlin.es/?sub=ML,CV,CG,NLP,RO,SP,DM,AP,KR,HCI" target="_blank" rel="nofollow" style="color: #483D8B"> AI Conference Deadlines </a> <br>
                </li>

                <li style="margin: 5px 0px 0px 0px">
                    <a href="https://ccf.atom.im/" target="_blank" rel="nofollow" style="color: #483D8B" > ccf.atom.im </a> <br>
                </li>

                <li style="margin: 5px 0px 0px 0px">
                    <a href="https://csrankings.org/#/index?all&sg" target="_blank" rel="nofollow" style="color: #483D8B"> Computer Science Rankings </a> <br>
                </li>

                <li style="margin: 5px 0px 0px 0px">
                    <a href="http://portal.core.edu.au/conf-ranks/" target="_blank" rel="nofollow" style="color: #483D8B"> Conference Portal </a> <br>
                </li>

                <li style="margin: 5px 0px 0px 0px">
                    <a target="_blank" href="resources/中国计算机学会推荐国际学术会议和期刊目录-2022.pdf" style="color: #483D8B">中国计算机学会推荐国际学术会议和期刊目录</a> <br>
                </li>

                <li style="margin: 5px 0px 0px 0px">
                    <a target="_blank" href="resources/中国计算机学会推荐中文科技期刊目录.pdf" style="color: #483D8B">中国计算机学会推荐中文科技期刊目录</a> <br>
                </li>

                <li style="margin: 5px 0px 0px 0px">
                    <a target="_blank" href="resources/中国计算机学会推荐计算领域高质量科技期刊分级目录.pdf" style="color: #483D8B">中国计算机学会推荐计算领域高质量科技期刊分级目录</a> <br>
                </li>

                <li style="margin: 5px 0px 0px 0px">
                    <a target="_blank" href="resources/清华大学计算机学科群推荐学术会议和期刊列表-2019.pdf" style="color: #483D8B">清华大学计算机学科群推荐学术会议和期刊列表</a> <br>
                </li>

                <li style="margin: 5px 0px 0px 0px">
                    <a target="_blank" href="resources/中国科协期刊分类-2024.pdf" style="color: #483D8B">中国科协高质量科技期刊分级目录总汇-2024 </a> <br>
                </li>
            </ul>
        </div>

        <!-- Visitor Map -->
        <div id="Maps" class="section">
            <h2 class="section-title">Visitor Map</h2>
            <div class="stats-counter">
                <script type="text/javascript" id="mapmyvisitors"
                  src="https://mapmyvisitors.com/map.js?cl=ffffff&w=557&t=tt&d=Ag-DLUyxYprkvEFDlsL7QoXf2fUFQ41ogt-7CsEBSto&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff">
                </script>
            </div>
        </div>

    </div>
    <footer>
        <p>This webpage is partly based on <a href="https://xianjie-guo.github.io/" target="_blank" style="color: #483D8B">Xianjie Guo</a>. Copyright © 2025 Hao Shen. All rights reserved.</p>
    </footer>
    <script>
        // 移动端菜单切换
        document.addEventListener('DOMContentLoaded', function() {
            // 改善移动端触摸体验
            if ('ontouchstart' in window) {
                document.documentElement.classList.add('touch-device');
            }
            
            // 移动端菜单优化
            const menuItems = document.querySelectorAll('.menu a');
            menuItems.forEach(item => {
                item.addEventListener('touchstart', function() {
                    this.classList.add('touch-active');
                });
                
                item.addEventListener('touchend', function() {
                    this.classList.remove('touch-active');
                });
            });
        });
    </script>
    <script>
        // 语言切换功能 - 优化移动端体验
        document.addEventListener('DOMContentLoaded', function() {
            const btnEn = document.getElementById('btn-en');
            const btnZh = document.getElementById('btn-zh');
            const enContent = document.getElementById('biography-en');
            const zhContent = document.getElementById('biography-zh');
            
            // 切换语言函数
            function switchLanguage(lang) {
                if (lang === 'zh') {
                    btnZh.classList.add('active');
                    btnEn.classList.remove('active');
                    zhContent.classList.add('active');
                    enContent.classList.remove('active');
                } else {
                    btnEn.classList.add('active');
                    btnZh.classList.remove('active');
                    enContent.classList.add('active');
                    zhContent.classList.remove('active');
                }
            }
            
            // 点击事件 - 使用更可靠的点击处理
            btnEn.addEventListener('click', function() {
                switchLanguage('en');
            });
            
            btnZh.addEventListener('click', function() {
                switchLanguage('zh');
            });
            
            // 移动端触摸优化
            if ('ontouchstart' in window) {
                // 添加触摸反馈
                const buttons = [btnEn, btnZh];
                
                buttons.forEach(button => {
                    // 触摸开始
                    button.addEventListener('touchstart', function(e) {
                        e.preventDefault();
                        this.classList.add('touch-active');
                    }, { passive: false });
                    
                    // 触摸结束
                    button.addEventListener('touchend', function(e) {
                        e.preventDefault();
                        this.classList.remove('touch-active');
                        
                        // 延迟执行切换，确保触摸反馈可见
                        setTimeout(() => {
                            if (this.id === 'btn-en') {
                                switchLanguage('en');
                            } else {
                                switchLanguage('zh');
                            }
                        }, 50);
                    }, { passive: false });
                    
                    // 触摸取消（如滑动离开按钮）
                    button.addEventListener('touchcancel', function() {
                        this.classList.remove('touch-active');
                    });
                });
            }
            
            // 移动端菜单优化（原有代码保持不变）
            if ('ontouchstart' in window) {
                document.documentElement.classList.add('touch-device');
            }
            
            const menuItems = document.querySelectorAll('.menu a');
            menuItems.forEach(item => {
                item.addEventListener('touchstart', function() {
                    this.classList.add('touch-active');
                });
                
                item.addEventListener('touchend', function() {
                    this.classList.remove('touch-active');
                });
            });
        });
    </script>
</body>
</html>
